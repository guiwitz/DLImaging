{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "# 3. Tensor calculations\n",
    "\n",
    "We have seen in the previous cahtper that we need to use a specific type of array (matrix) in the frame of PyTorch based neural networks, namely tensors. These tensors are very similar to Numpy arrays but with additional specific functionalities needed for deep learning. There is an ongoing effort to make the switch between different array/tensor formats (numpy, tensors, xarray etc.) more transparent in the future, but for the moment let's briefly explore the PyTorch tensors, accessible from the ```torch``` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating arrays\n",
    "\n",
    "Numpy and Pytorch share a lot of functions and methods so you wont feel completely lost. For example you can create arrays filled with ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_array = torch.ones((3,2))\n",
    "t_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_array = np.ones((3,2))\n",
    "n_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also find the type of the array with ```dtype```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_array dtype: torch.float32\n",
      "n_array dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f't_array dtype: {t_array.dtype}')\n",
    "print(f'n_array dtype: {n_array.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch implements as well many other function to create arrays that are very similar to Numpy. For example random number arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_random = torch.randint(0,255,(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally you can easily transform Numpy arrays into Pytorch tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_from_n = torch.tensor(n_array)\n",
    "t_from_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the reverse is true as well: you can recover a Numpy array from a Pytorch tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_from_n.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, Pytorch tensors are also compatible with Matplotlib, so you can easily have a look at them using e.g. ```imshow``` for 2D tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(t_random);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing, broadcasting etc.\n",
    "\n",
    "The powerful logic behind Numpy that allows for a very efficient selection and combination of elements in arrays is also conserved in Pytorch. For example regular indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 12, 244, 194, 123,  42,  58,  68, 106, 184, 145],\n",
       "        [216,  50, 204, 170, 249, 175, 128, 228, 209, 121],\n",
       "        [206,  49,  94,  55, 232,  34, 143,  36,  88, 213],\n",
       "        [111, 149, 183, 253,  87, 170, 233, 115,  20, 122],\n",
       "        [ 99,   4, 223,  95,  17,  70,  37, 210,  49, 193],\n",
       "        [118,  22,  54, 224, 166, 125, 138, 121, 220, 174],\n",
       "        [228,  48, 224, 221, 181, 234,  44, 103,  52, 152],\n",
       "        [162,   6, 241, 213,  27, 164,  40, 103, 150, 115],\n",
       "        [177,  27, 103, 163, 177, 219, 106, 135, 184, 109],\n",
       "        [ 81,  90, 124, 202, 237,  96, 164,  41, 100,  74]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 12, 244, 194, 123,  42,  58,  68, 106, 184, 145])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_random[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or broadcasting that allows to combine tensors of different but compatible shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[174., 152.,  77.,  20.,   8.],\n",
       "        [174., 152.,  77.,  20.,   8.],\n",
       "        [174., 152.,  77.,  20.,   8.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((3,5)) * torch.randint(0,255, (1,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see that very often we also need to flatten arrays for example to create a fully connected layer in a deep learning network. This can be done in two ways. You can use the ```flatten``` function/method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 12, 244, 194, 123,  42,  58,  68, 106, 184, 145, 216,  50, 204, 170,\n",
       "        249, 175, 128, 228, 209, 121, 206,  49,  94,  55, 232,  34, 143,  36,\n",
       "         88, 213, 111, 149, 183, 253,  87, 170, 233, 115,  20, 122,  99,   4,\n",
       "        223,  95,  17,  70,  37, 210,  49, 193, 118,  22,  54, 224, 166, 125,\n",
       "        138, 121, 220, 174, 228,  48, 224, 221, 181, 234,  44, 103,  52, 152,\n",
       "        162,   6, 241, 213,  27, 164,  40, 103, 150, 115, 177,  27, 103, 163,\n",
       "        177, 219, 106, 135, 184, 109,  81,  90, 124, 202, 237,  96, 164,  41,\n",
       "        100,  74])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_random.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can also specify which *contiguous* dimensions you want to flatten e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[21, 52, 46, 33],\n",
       "         [ 4, 67, 90, 59],\n",
       "         [77, 69, 30, 92]],\n",
       "\n",
       "        [[29, 95, 98, 22],\n",
       "         [33, 28,  0, 78],\n",
       "         [92, 95, 95, 30]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_3d = torch.randint(0,100,(2,3,4))\n",
    "t_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21, 52, 46, 33,  4, 67, 90, 59, 77, 69, 30, 92],\n",
       "        [29, 95, 98, 22, 33, 28,  0, 78, 92, 95, 95, 30]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(t_3d, start_dim=1, end_dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The alternative is to use the ```view``` method, which, if possible, returns only a ```view``` of the array. You can pass compatible dimensions to reshape the tensor, or simple use ```-1``` to completely flatten it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_random = torch.randint(0,255,(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 52, 217,  39, 216,  98,  16, 253, 182, 137,  97,  92, 235,  91,  87,\n",
       "         183, 120, 132, 188, 138, 146],\n",
       "        [162, 232,  44, 170, 214, 240, 181, 168,  49,  59,  28, 216,   4,  44,\n",
       "         219,  16, 187,   3,  99,  58],\n",
       "        [ 95,  12, 241, 205, 158,  46, 144,  88, 101,  64, 106,  86,  93,  16,\n",
       "         156,  57, 226, 233,  90, 175],\n",
       "        [ 45, 167, 159, 160,  68, 171,  16, 189, 203, 193, 251,   4, 139, 190,\n",
       "         172,  63,  53,  26, 151, 173],\n",
       "        [ 31,  66,  32, 231,  27,   3, 165,  75, 209,  53, 210,  79,  24, 169,\n",
       "         166, 188, 115,  48, 173, 122]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_random.view(5, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 52, 217,  39, 216,  98,  16, 253, 182, 137,  97,  92, 235,  91,  87,\n",
       "        183, 120, 132, 188, 138, 146, 162, 232,  44, 170, 214, 240, 181, 168,\n",
       "         49,  59,  28, 216,   4,  44, 219,  16, 187,   3,  99,  58,  95,  12,\n",
       "        241, 205, 158,  46, 144,  88, 101,  64, 106,  86,  93,  16, 156,  57,\n",
       "        226, 233,  90, 175,  45, 167, 159, 160,  68, 171,  16, 189, 203, 193,\n",
       "        251,   4, 139, 190, 172,  63,  53,  26, 151, 173,  31,  66,  32, 231,\n",
       "         27,   3, 165,  75, 209,  53, 210,  79,  24, 169, 166, 188, 115,  48,\n",
       "        173, 122])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_random.view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are dealing with a ```view```, if we modify one of the arrays *in place*, the values in the other arrays are changed as well. This means that this is **not** and independent array but just a shallow-copy. Therefore be *careful*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 52, 217,  39, 216,  98,  16, 253, 182, 137,  97,  92, 235,  91,  87,\n",
       "         183, 120, 132, 188, 138, 146],\n",
       "        [162, 232,  44, 170, 214, 240, 181, 168,  49,  59,  28, 216,   4,  44,\n",
       "         219,  16, 187,   3,  99,  58],\n",
       "        [ 95,  12, 241, 205, 158,  46, 144,  88, 101,  64, 106,  86,  93,  16,\n",
       "         156,  57, 226, 233,  90, 175],\n",
       "        [ 45, 167, 159, 160,  68, 171,  16, 189, 203, 193, 251,   4, 139, 190,\n",
       "         172,  63,  53,  26, 151, 173],\n",
       "        [ 31,  66,  32, 231,  27,   3, 165,  75, 209,  53, 210,  79,  24, 169,\n",
       "         166, 188, 115,  48, 173, 122]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_copy = t_random.view(5,20)\n",
    "view_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_copy.fill_(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to perform backpropagation in Deep Learning networks, we need to be able to calculate all the necessary gradients. This feature is \"integrated\" into Pytorch arrays directly if we use the ```requires_grad``` option. To start with a simple example, let's define first a variable $x=1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(1, 1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.]], requires_grad=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we let our variable pass through a few simple operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y**(3/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 5 * z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our last variable that depends initially on ```x``` is now ```w```. We see that $w = f(z) = f(g(y)) = f(g(h(x))) = k(x)$ with:\n",
    "\n",
    "$f(z) = 5*z$\n",
    "\n",
    "$g(y) = y^{3/2}$\n",
    "\n",
    "$h(x) = 2*x$\n",
    "\n",
    "If ```w``` needs to be optimized with respect to the variablex x, following th chain rule, we need to calculate $k'(x) = f'(g(h(x))*g'(h(x))*h'(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$5 * \\frac{3}{2}(2x)^{0.5} * 2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This complete calculation can simply be performed by calcualting the gradients of w $dw/dx$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[21.2132]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that we indeed obtain the correct gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.213203435596427"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5 * (3/2)*(2**0.5) * 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course this is an over-simplified example. Calculations become more complex when dealing with actual vectors or tensors but the principle remains the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally note that if you want to recover a Numpy array from a PyTorch tensor, or plot a PyTorch tensor with Matplotlib, you first have to *detach* it from the gradient calculation system (if necessary) to recover it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-2527552080a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending tensors to a GPU\n",
    "\n",
    "If your computer is equipped with a compatible GPU or if you run the notebook on Google Colab with a GPU runtime, you can exploit Graphics card computing power. For that the data have to be \"pushed\" and \"pulled\" to and from that device. We will see later that we can push entire networks thre but for the moment we just send a tensor.\n",
    "\n",
    "First we have to check wheter a GPU is available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If yes we can device a GPU device (a CUDA device in fact):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can send the data the the \"CUDA\" device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytensor = torch.randn((3,5))\n",
    "mytensor.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9206,  1.6913, -0.8548,  0.3654,  0.2427],\n",
       "        [-0.6904, -1.3062, -1.7042,  1.0760, -0.5222],\n",
       "        [ 0.7305, -2.2660,  0.3102,  0.1640,  1.1676]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytensor.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that we have again difficulties getting the tensor \"out\" of PyTorch. This time not because it's part of a gradient but because it lives on the GPU. So we need to first copy it back to the CPU first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytensor_CPU = mytensor.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytensor_CPU.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will regularly hit this kind of problems when writing your code, so remember these two potential issues when you want to *post-process* some tensor:\n",
    "- you migth need to *detach* it from the gradient calculation\n",
    "- you migth need to pull it out of the GPU\n",
    "- for NN computation, you might need to push your data (tensors) to the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "290.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
