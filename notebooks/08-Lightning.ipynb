{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/guiwitz/DLImaging/blob/master/notebooks/08-Lightning.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Simplifying code with PyTorch-Lightning\n",
    "\n",
    "We have seen in the previous chapter how to train a neural network. Our training loop contained a lot of \"boiler-plate\" code, i.e. trivial things that we always need, like ```loss.backwards()```, and that we would like to spare us to write. Several libraries offer such possibilities, the most popular one being PyTorch Lightning. We will here briefly rewrite our code of the [Training](Training.ipynb) notebook with this. You will see that we write essentially the same code, save for some boiler-plate.\n",
    "\n",
    "Another advantage is that the higher-level format offered by Lightning allows us later to simplify complex tasks, like traininig on multiple GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# set path containing data folder or use default for Colab (/gdrive/My Drive)\n",
    "local_folder = \"../\"\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/guiwitz/DLImaging/master/utils/check_colab.py', 'check_colab.py')\n",
    "from check_colab import set_datapath\n",
    "colab, datapath = set_datapath(local_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "We recreate first some previous elements. First our dataset and dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.functional import F\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load(datapath.joinpath('data/triangle_circle.npy'))\n",
    "labels = np.load(datapath.joinpath('data/triangle_circle_label.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tricircle(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        super(Tricircle, self).__init__()\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        x = self.data[index]\n",
    "        x = torch.tensor(x/255, dtype=torch.float32)\n",
    "        y = torch.tensor(self.labels[index])\n",
    "        #y = torch.randint(0,2,(1,))[0]#create random labels as \"bad\" examples\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tridata = Tricircle(images, labels)\n",
    "test_size = int(0.8 * len(tridata))\n",
    "valid_size = len(tridata)-test_size\n",
    "\n",
    "train_data, valid_data = random_split(tridata, [test_size, valid_size])\n",
    "train_loader = DataLoader(train_data, batch_size=10)\n",
    "validation_loader = DataLoader(valid_data, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightning module\n",
    "\n",
    "Before, we only created an object containing our model and all the remaining tasks - setting up the optimizer, training and validation loop etc. - was done after that \"manually\". Here, all this additional work is included in our object in specific methods (```training_step```, ```validation_step```, ```configure_optimizers```) sparing us a lot of code later on. For example we won't have to explicitly write epochs and batch loops, take care of calculating gradients, setting them to zeros etc.\n",
    "\n",
    "You should understand one important feature of Ligthning: the ```forward``` function is used for **inference** (prediction) while the ```training_step``` is used for **training**. Of course one can include the steps of ```forward``` in the training loop but the latter can contain much more information.\n",
    "\n",
    "The actual difference in code is very small compared to classic PyTorch but brings massive advantages. Of importance in my personal opinion: Lightning *organizes* code and doesn't abstract away complexity. This makes it easy to still do very fine adjustments to the underlying PyTorch code what other higher-level frameworks make difficult.\n",
    "\n",
    "This was our previous code defining our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mynetwork(nn.Module):\n",
    "    def __init__(self, input_size, num_categories):\n",
    "        super(Mynetwork, self).__init__()\n",
    "        \n",
    "        # define e.g. layers here e.g.\n",
    "        self.layer1 = nn.Linear(input_size, 100)\n",
    "        self.layer2 = nn.Linear(100, num_categories)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # flatten the input\n",
    "        x = x.flatten(start_dim=1)\n",
    "        # define the sequence of operations in the network including e.g. activations\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = self.layer2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add methods for training, validation and optimizer which are basically copied from our previous work. Note however that we can skip many things, like loops or ```backward()``` calls. The only thing that we are adding are calls to ```self.log``` which allows us to capture and display loss, accuracy etc. information during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mynetwork(pl.LightningModule):\n",
    "    def __init__(self, input_size, num_categories):\n",
    "        super(Mynetwork, self).__init__()\n",
    "        \n",
    "        # define e.g. layers here e.g.\n",
    "        self.layer1 = nn.Linear(input_size, 100)\n",
    "        self.layer2 = nn.Linear(100, num_categories)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # flatten the input\n",
    "        x = x.flatten(start_dim=1)\n",
    "        # define the sequence of operations in the network including e.g. activations\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = self.layer2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        x, y = batch\n",
    "        output = self(x)\n",
    "        loss = self.loss(output, y)\n",
    "        \n",
    "        self.log('loss', loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        x, y = batch\n",
    "        output = self(x)\n",
    "        accuracy = (torch.argmax(output,dim=1) == y).sum()/len(y)\n",
    "\n",
    "        self.log('accuracy', accuracy, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        return accuracy\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we instantiate the Lightning module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Mynetwork(32*32, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Instead of writing a training loop for epochs and batches, we use the Lightning ```Trainer``` object which takes care of everything for us. We first instantiate it and then pass our model and data loaders for fitting (similarly to scikit-learn methods)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type             | Params\n",
      "--------------------------------------------\n",
      "0 | layer1 | Linear           | 102 K \n",
      "1 | layer2 | Linear           | 202   \n",
      "2 | loss   | CrossEntropyLoss | 0     \n",
      "--------------------------------------------\n",
      "102 K     Trainable params\n",
      "0         Non-trainable params\n",
      "102 K     Total params\n",
      "0.411     Total estimated model params size (MB)\n",
      "/Users/gw18g940/miniconda3/envs/CASImaging/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /Users/gw18g940/GoogleDrive/BernMIC/Trainings/CAS_DLimaging/CASImaging/notebooks/lightning_logs/version_1/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                              "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gw18g940/miniconda3/envs/CASImaging/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/gw18g940/miniconda3/envs/CASImaging/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 5000/5000 [00:38<00:00, 129.13it/s, loss=0.0054, v_num=1, loss_step=0.000345, accuracy=0.998, loss_epoch=0.027]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=validation_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "To check that trainig worked, we just generate again some images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlcourse import make_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_type = ['triangle', 'circle']\n",
    "label = torch.tensor(np.random.randint(0,2,100))\n",
    "mybatch = torch.stack([make_image(im_type[x]) for x in label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 32, 32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybatch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(mybatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "        0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "        0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "        0, 0, 0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "        0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "        0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "        0, 0, 0, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(confusion_matrix(pred.argmax(dim=1), label), index = im_type,\n",
    "                  columns = im_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a logger\n",
    "\n",
    "It is very common to use an additional tool to follow the progress of training. A very popular tool is TensorBoard. To use it with PyTorch Lightening, we can simply attach a TensorBoard logger to our trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mynetwork(pl.LightningModule):\n",
    "    def __init__(self, input_size, num_categories):\n",
    "        super(Mynetwork, self).__init__()\n",
    "        \n",
    "        # define e.g. layers here e.g.\n",
    "        self.layer1 = nn.Linear(input_size, 100)\n",
    "        self.layer2 = nn.Linear(100, num_categories)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # flatten the input\n",
    "        x = x.flatten(start_dim=1)\n",
    "        # define the sequence of operations in the network including e.g. activations\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = self.layer2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        x, y = batch\n",
    "        output = self(x)\n",
    "        \n",
    "        loss = self.loss(output, y)\n",
    "        accuracy = (torch.argmax(output,dim=1) == y).sum()/len(y)\n",
    "        \n",
    "        #self.log('loss', loss, on_epoch=True, prog_bar=True, logger=False)\n",
    "        self.logger.experiment.add_scalar(\"Loss/Train\", loss, self.current_epoch)\n",
    "        self.logger.experiment.add_scalar(\"Accuracy/Train\", accuracy, self.current_epoch)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        x, y = batch\n",
    "        output = self(x)\n",
    "        \n",
    "        loss = self.loss(output, y)\n",
    "        accuracy = (torch.argmax(output,dim=1) == y).sum()/len(y)\n",
    "\n",
    "        #self.log('accuracy', accuracy, on_epoch=True, prog_bar=True, logger=False)\n",
    "        self.logger.experiment.add_scalar(\"Loss/Train\", loss, self.current_epoch)\n",
    "        self.logger.experiment.add_scalar(\"Accuracy/Valid\", accuracy, self.current_epoch)\n",
    "        \n",
    "        return accuracy\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Mynetwork(32*32, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We added here logging of the accuracy and loss for both training and validation using the ```add_scalar``` method. You can find more details in the [PyTorch API](https://pytorch.org/docs/stable/tensorboard.html).\n",
    "\n",
    "Now we create a tensorboard logger and pass it to our trainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"my_model\")\n",
    "trainer = pl.Trainer(logger=logger, max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type             | Params\n",
      "--------------------------------------------\n",
      "0 | layer1 | Linear           | 102 K \n",
      "1 | layer2 | Linear           | 202   \n",
      "2 | loss   | CrossEntropyLoss | 0     \n",
      "--------------------------------------------\n",
      "102 K     Trainable params\n",
      "0         Non-trainable params\n",
      "102 K     Total params\n",
      "0.411     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  17%|█▋        | 832/5000 [01:00<05:02, 13.80it/s, loss=0.269, v_num=2]\n",
      "                                                              "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gw18g940/miniconda3/envs/CASImaging/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/gw18g940/miniconda3/envs/CASImaging/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  34%|███▍      | 1705/5000 [00:41<01:19, 41.23it/s, loss=0.00888, v_num=2] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gw18g940/miniconda3/envs/CASImaging/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9b9e24497b1a3cbc\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9b9e24497b1a3cbc\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir tb_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running on the GPU\n",
    "\n",
    "We have seen in a previous notebook that in order to use a GPU we need to send models and data to it. This is much simplified with Lightning, as you just have to tell the trainer to use a GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(logger=logger, max_epochs=10, gpus=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "We have seen here and in the previous chapters how to create datasets, dataloaders, transforms and a easily trainable Lightning-network. In a previous exercise you have in particular created a dataloader for the quickdraw dataset. Extend this now by creating a Lightninig-network with a simple NN similar to the one used here. Try to train it. (Answer is notebook [09-Classify_drawings](09-Classify_drawings.ipynb))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
