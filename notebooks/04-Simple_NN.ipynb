{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AI1uO_bdYDRH"
   },
   "source": [
    "# 4. Simple neural net with PyTorch\n",
    "\n",
    "Neural networks can be programmed on different levels depending on how much one needs to customize either the architecture or the training pattern. When dealing with more complex NN we will use a higher-level package (Lightning, see [Chapter 8](08-Lightning.ipynb)) which will spare us some \"manual\" work. However, in order to understand all steps involved in designing a DL algorithm, we will first use basic PyTroch. In this notebook we will see howe we can *design* a NN while in [the next notebook](05-Training.ipynb) we will se how to train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path containing data folder or use default for Colab (/gdrive/My Drive)\n",
    "local_folder = \"../\"\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/guiwitz/DLImaging/master/utils/check_colab.py', 'check_colab.py')\n",
    "from check_colab import set_datapath\n",
    "colab, datapath = set_datapath(local_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn\n",
    "\n",
    "We will see in this notebook how to create a simple neural network for image classification using the most general mechanism in PyTorch which are modules. All module-related objects and functions are contained in ```torch.nn```. As the name indicates, these modules are really *modular* in the sense that they are indpendent parts of networks that can be combined together. Mostly we will use single modules containing the multiple layers of our architecture, but we will also see examples where multiple modules are assembled.\n",
    "\n",
    "A module is essentially an assemble of multiple other modules, and many of these are provided \"pre-made\" for us also available in ```torch.nn```. For example in the simple network used here we will only use linear layers (fully connected) which we will integrate in a general ```nn.Module```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4633,
     "status": "ok",
     "timestamp": 1610065427087,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "YL9Tx6P0YDRM"
   },
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvslIDeUYDRN"
   },
   "source": [
    "In addition to *layers* we will typically also need activation function such as soft-max. Those are implemnted in ```torch.nn.functional``` which we import separately (by convention):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 4629,
     "status": "ok",
     "timestamp": 1610065427088,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "2-uqNcAGYDRN"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzPIWGlLYDRN"
   },
   "source": [
    "## Structure of a network\n",
    "\n",
    "Any network can be built as a subclass of the base ```torch.nn.Module``` class. The only things that we need to specify are the inputs that we need (```myparameter1, myparameter2```) as well as the ```forward``` function, which describes the network itself. Here's the \"skeleton\" of that object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1047,
     "status": "ok",
     "timestamp": 1610065432065,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "-orgrI3IYDRO"
   },
   "outputs": [],
   "source": [
    "class Mynetwork(nn.Module):\n",
    "    def __init__(self, myparameter1, myparameter2):\n",
    "        super(Mynetwork, self).__init__()\n",
    "        \n",
    "        # define e.g. layers here e.g.\n",
    "        self.layer1 = nn.Linear(myparameter1, myparameter2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # define the sequence of operations in the network including e.g. activations\n",
    "        x = F.relu(self.layer1(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ij-rK7HkYDRO"
   },
   "source": [
    "Above, we have defined a simple network that is defined by two parameters and which is composed of a single linear layer followed by a ReLU unit. The differnt layers that we need are defined in ```__init__``` as object parameters and then re-used in the network definition in the ```forward``` function. ```forward``` takes an input ```x``` (e.g.g an image to classify), passes it through the network and outputs the result. Therefore in principle we could instantiate a model and use it like this:\n",
    "\n",
    "```\n",
    "mymodel = Mynetwork(5,10)\n",
    "mymodel.forward(myinput)\n",
    "```\n",
    "\n",
    "*However, ```nn.Module``` has a ```__call__``` attribute that allows us to use the class as a function like this:\n",
    "\n",
    "```\n",
    "mymodel = Mynetwork(5,10)\n",
    "mymodel(myinput)\n",
    "```\n",
    "\n",
    "This is actually **how a module should be properly used** in order to exploit all capabilities offered in PyTorch.\n",
    "\n",
    "Let's now try this out. We instantiate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 660,
     "status": "ok",
     "timestamp": 1610065434681,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "4nhXAob2YDRO"
   },
   "outputs": [],
   "source": [
    "mymodel = Mynetwork(5,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBL1nCf6YDRP"
   },
   "source": [
    "The ```mymodel``` instance has many methods attached. We can simply print the model in the notebook: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 620,
     "status": "ok",
     "timestamp": 1610065436476,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "HXGXjCKdYDRP",
    "outputId": "cbf73c4a-bbc5-48c8-dadd-ab24d34174f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mynetwork(\n",
       "  (layer1): Linear(in_features=5, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vht79uk8YDRQ"
   },
   "source": [
    "Or we can also explicitly get all modules of our network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 507,
     "status": "ok",
     "timestamp": 1610065438627,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "IlgexYZ6YDRQ",
    "outputId": "647de5b8-6e3d-4e75-a5e9-6f28af8b401f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> Mynetwork(\n",
      "  (layer1): Linear(in_features=5, out_features=10, bias=True)\n",
      ")\n",
      "1 -> Linear(in_features=5, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for idx, m in enumerate(mymodel.modules()):\n",
    "    print(idx, '->', m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kB3s13AYDRQ"
   },
   "source": [
    "Or we can just find all modules contained in our main module and recover its name and function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 512,
     "status": "ok",
     "timestamp": 1610065440522,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "kp8wjdEPYDRQ",
    "outputId": "b1c92855-78e6-450f-bcca-28dd9d3ccd28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: layer1 module: Linear(in_features=5, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for name, module in mymodel.named_children():\n",
    "    print(f'name: {name} module: {module}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4KPXjgsYDRR"
   },
   "source": [
    "We also have access to all the parameters of the model, either with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 650,
     "status": "ok",
     "timestamp": 1610065442107,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "Tq9xbzeUYDRR",
    "outputId": "f444683c-1133-4a97-f7cf-cfaadfda05a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.1298, -0.1587, -0.3077,  0.0653,  0.1296],\n",
       "         [ 0.1329, -0.0619,  0.2880,  0.3090,  0.2891],\n",
       "         [-0.2692, -0.0924,  0.2699, -0.1082, -0.1088],\n",
       "         [-0.3235, -0.3730,  0.2498, -0.0414,  0.1177],\n",
       "         [ 0.4275, -0.0031, -0.3828,  0.1921, -0.3106],\n",
       "         [-0.3430,  0.1405, -0.2762,  0.3789, -0.1412],\n",
       "         [ 0.2861, -0.0035,  0.2028, -0.1285, -0.3484],\n",
       "         [-0.3250,  0.2826, -0.1498,  0.3456,  0.1819],\n",
       "         [-0.4376, -0.0918, -0.0750,  0.1418,  0.1103],\n",
       "         [-0.2162,  0.3977,  0.4417,  0.3184, -0.1239]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0513, -0.0930,  0.2187, -0.3819, -0.3960,  0.2344, -0.0983,  0.2018,\n",
       "          0.1288,  0.2878], requires_grad=True)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mymodel.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lmhrocc9YDRR"
   },
   "source": [
    "or by returning a dictionary of layers with their names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 525,
     "status": "ok",
     "timestamp": 1610065444665,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "1MrDaJ4hYDRR",
    "outputId": "20c0d36d-d842-4fed-bcee-973ac6316436"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer1.weight',\n",
       "              tensor([[-0.1298, -0.1587, -0.3077,  0.0653,  0.1296],\n",
       "                      [ 0.1329, -0.0619,  0.2880,  0.3090,  0.2891],\n",
       "                      [-0.2692, -0.0924,  0.2699, -0.1082, -0.1088],\n",
       "                      [-0.3235, -0.3730,  0.2498, -0.0414,  0.1177],\n",
       "                      [ 0.4275, -0.0031, -0.3828,  0.1921, -0.3106],\n",
       "                      [-0.3430,  0.1405, -0.2762,  0.3789, -0.1412],\n",
       "                      [ 0.2861, -0.0035,  0.2028, -0.1285, -0.3484],\n",
       "                      [-0.3250,  0.2826, -0.1498,  0.3456,  0.1819],\n",
       "                      [-0.4376, -0.0918, -0.0750,  0.1418,  0.1103],\n",
       "                      [-0.2162,  0.3977,  0.4417,  0.3184, -0.1239]])),\n",
       "             ('layer1.bias',\n",
       "              tensor([-0.0513, -0.0930,  0.2187, -0.3819, -0.3960,  0.2344, -0.0983,  0.2018,\n",
       "                       0.1288,  0.2878]))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-Kp9kzeYDRR"
   },
   "source": [
    "## Passing an input\n",
    "\n",
    "Now that we have a (very) basic network we can try to pass an input through it. Since our first layer has length 10 we define a vector of length 10 in numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 502,
     "status": "ok",
     "timestamp": 1610065446596,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "BrpgmCV9YDRS"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 604,
     "status": "ok",
     "timestamp": 1610065481351,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "WgH4jbSpYDRS",
    "outputId": "1db57c13-14cc-458e-d140-5b7880fdb913"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 20, 57, 36, 32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myvector = np.random.randint(0,100,5)\n",
    "myvector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXXbN8u2YDRS"
   },
   "source": [
    "No we we pass it to ```mymodel```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "executionInfo": {
     "elapsed": 717,
     "status": "error",
     "timestamp": 1610065483170,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "lSXkG3RfYDRS",
    "outputId": "5473b837-42ca-48b2-e573-3031442deb95",
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-429eaacc742b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmymodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/CASImaging/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-4f41668e2067>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# define the sequence of operations in the network including e.g. activations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/CASImaging/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/CASImaging/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/CASImaging/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtens_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "mymodel(myvector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dR4xQZciYDRS"
   },
   "source": [
    "Of course we get an error, as the network doesn't expect a numpy array but a PyTorch tensor! We can have a look at what PyTorch tensors are in the [03-Tensors](03-Tensors.ipynb) notebooks and come back here later.\n",
    "\n",
    "Now we can turn our Numpy array into a tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 565,
     "status": "ok",
     "timestamp": 1610065485142,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "lNz6N6ZgYDRT"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 367,
     "status": "ok",
     "timestamp": 1610065485503,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "eHX1lbiCYDRT",
    "outputId": "63f442c7-7567-4469-f3de-e40c6e9dda7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 20, 57, 36, 32])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytensor = torch.tensor(myvector)\n",
    "mytensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "executionInfo": {
     "elapsed": 407,
     "status": "error",
     "timestamp": 1610065486424,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "m_-lAb5SYDRT",
    "outputId": "f98b9767-5d07-433f-e7e7-b316845b8663",
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d7e88d40c12d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmymodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmytensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/CASImaging/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-4f41668e2067>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# define the sequence of operations in the network including e.g. activations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/CASImaging/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/CASImaging/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/CASImaging/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
     ]
    }
   ],
   "source": [
    "mymodel(mytensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lV6W7QoJYDRT"
   },
   "source": [
    "Again an error! The error can be a bit misleading. The whole problem is that the weights in the network are defined by default as ```float32```. Hence the input should match this but we passed an 64 bits integer which creates a conflict. Let's adjust the type of our tensor. We can either modify the tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 620,
     "status": "ok",
     "timestamp": 1610065490239,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "eCYVteuRYDRT"
   },
   "outputs": [],
   "source": [
    "mytensor_float = mytensor.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 830,
     "status": "ok",
     "timestamp": 1610065491111,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "MnABMWbkYDRU",
    "outputId": "aed5ad21-e85c-43a9-ff03-84bd5e08bb75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1., 20., 57., 36., 32.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytensor_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 508,
     "status": "ok",
     "timestamp": 1610065491323,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "9aj1UP4ZYDRU",
    "outputId": "ad68be78-f126-44c1-ea76-212ac6b66c41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytensor_float.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or do it from the beginning when transforming our Numpy array by specifying the ```dtype``` explicitely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytensor_float = torch.tensor(myvector, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytensor_float.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we finally have the right object to path through our network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 406,
     "status": "ok",
     "timestamp": 1610065492214,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "wwrmvWgcYDRU",
    "outputId": "a8e64d64-55d7-46da-8021-45365708dc7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000, 35.5923,  6.1060,  8.3526,  0.0000,  0.0000,  0.0000, 15.2542,\n",
       "         2.2178, 40.6967], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = mymodel(mytensor_float)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 520,
     "status": "ok",
     "timestamp": 1610065494958,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "-6bOnr9bYDRU",
    "outputId": "4f753749-515d-4425-fb9d-e4b4b6186cff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKI4bj_YYDRU"
   },
   "source": [
    "### Batches\n",
    "\n",
    "If we want to use batch processing, we can also pass batches of vectors thourgh the network instead of single vectors. PyTroch layers are designed to hanle this by default, so here for example if we want to use a batch of size 32 we can just use a 32 x 10 tensor. We create one directly with ```torch.randn```here (we will learn more about batches in the chapter on training):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 576,
     "status": "ok",
     "timestamp": 1610065511425,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "b2FsgyCfYDRV",
    "outputId": "ae1ae915-54bd-402a-d963-eef0052600f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 5])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_tensor = torch.randn(32,5)\n",
    "batch_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1610065512351,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "bYAmmXLwYDRV"
   },
   "outputs": [],
   "source": [
    "batch_output = mymodel(batch_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 690,
     "status": "ok",
     "timestamp": 1610065516126,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "UP48jBj2YDRV",
    "outputId": "8adf830c-c1de-465f-c53f-b7c3b7fbeea7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the output is \"batched\" as well, so the network gracefully handlend this batch for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dm35UQ76YDRV"
   },
   "source": [
    "### Passing an image as input\n",
    "\n",
    "For the tests above, we simply used vectors. However our goal is to pass images to our network. As our network is linear and fully connected, we therefore need to pass a flattened (1D) version of our image. We have seen before that we can do that using the ```view``` method or ```flatten```.\n",
    "\n",
    "To test this, we first create a test image using the ```skimage.draw``` utility scikit-image which allows us to create ```random_shapes``` images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 560,
     "status": "ok",
     "timestamp": 1610065523234,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "oWDgsh30YDRV"
   },
   "outputs": [],
   "source": [
    "from skimage.draw import random_shapes\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a 32x32 image of a circle. We have multiple options for the number of shapes, their size etc. to select from. We also invert the image (to have the *object* as foreground):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 375,
     "status": "ok",
     "timestamp": 1610065523543,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "fJrw_f5SYDRV"
   },
   "outputs": [],
   "source": [
    "image_circle, _ = random_shapes((32,32),max_shapes=1, min_shapes=1,multichannel=False, shape='circle',\n",
    "                                min_size=8, random_seed=2)\n",
    "image_circle = 255-image_circle\n",
    "\n",
    "image_tensor = torch.tensor(image_circle,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "executionInfo": {
     "elapsed": 658,
     "status": "ok",
     "timestamp": 1610065524861,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "4EFYRWMBYDRW",
    "outputId": "7edbbcb8-79e2-4161-ff2f-0b82f457290b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image_tensor, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we flatten the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 483,
     "status": "ok",
     "timestamp": 1610065525997,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "tK7em6_XYDRW",
    "outputId": "979aea7b-6159-44bd-f0d5-4721056cffc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_flat = image_tensor.view(-1)\n",
    "image_flat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugGq_DqGYDRW"
   },
   "source": [
    "We adjust our network input size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 683,
     "status": "ok",
     "timestamp": 1610065527813,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "YKDedfAmYDRW"
   },
   "outputs": [],
   "source": [
    "mymodel = Mynetwork(1024,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1610065528756,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "2nHvFUbUYDRW"
   },
   "outputs": [],
   "source": [
    "output = mymodel(image_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 647,
     "status": "ok",
     "timestamp": 1610065532219,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "B4I8aSoSYDRX",
    "outputId": "b7a50671-246e-4151-c8d8-85b0b30fc788"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([28.6390,  0.0000,  7.9412, 11.6821,  9.4355, 61.6182,  0.0000,  0.0000,\n",
       "        37.3092,  0.0000, 27.1674, 54.1358,  0.0000,  1.5281,  0.0000,  0.0000,\n",
       "        50.4064,  0.0000,  0.0000,  4.4874], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjTKDBKJYDRX"
   },
   "source": [
    "The operation of \"flattening\" can be done at different places. For example, instead of flattening the input, we can also flatten within our network definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 584,
     "status": "ok",
     "timestamp": 1610065538567,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "Xg_6FfmmYDRX"
   },
   "outputs": [],
   "source": [
    "class Mynetwork2(nn.Module):\n",
    "    def __init__(self, myparameter1, myparameter2):\n",
    "        super(Mynetwork2, self).__init__()\n",
    "        \n",
    "        # define e.g. layers here e.g.\n",
    "        self.layer1 = nn.Linear(myparameter1, myparameter2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.view(-1)\n",
    "        # define the sequence of operations in the network including e.g. activations\n",
    "        x = F.relu(self.layer1(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 531,
     "status": "ok",
     "timestamp": 1610065539912,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "FVwBTjLfYDRX"
   },
   "outputs": [],
   "source": [
    "second_model = Mynetwork2(1024, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "ok",
     "timestamp": 1610065540661,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "yTj4dIzkYDRX",
    "outputId": "871ca0bf-22e3-4820-b078-5c19d83cf684"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 638,
     "status": "ok",
     "timestamp": 1610065542870,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "1de0QvgnYDRY",
    "outputId": "5dd4db98-d8ce-4dd2-db31-fe525d407371"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([58.9915,  0.0000,  0.0000,  0.0000,  0.0000, 30.0834,  0.0000, 30.6602,\n",
       "         0.0000,  0.0000,  0.0000,  0.0000, 27.1779,  0.0000, 44.7265,  0.0000,\n",
       "        13.0921, 47.9660,  0.0000,  0.0000], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = second_model(image_tensor)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 749,
     "status": "ok",
     "timestamp": 1610065544375,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "LB7DUByhYDRY",
    "outputId": "56dc6213-3dba-4997-c1f2-53d0e5e28b94"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87EQqckMYDRY"
   },
   "source": [
    "## Saving and loading a model\n",
    "\n",
    "Our next goal will be to train our network (see next chapter). At some point during or after training we will want to save both our model and its weights. This can be done in two ways.\n",
    "\n",
    "### Save full model\n",
    "\n",
    "First, we can save the entire model so that it can be simply reloaded. This is practical when developing but can lead to problems when moving saved models between computers. First we save our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "OYkt0Fw0YDRY"
   },
   "outputs": [],
   "source": [
    "torch.save(second_model, datapath.joinpath('models/simpleNN.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVR_snhCYDRZ"
   },
   "source": [
    "And reload it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "e4sjsS7KYDRZ"
   },
   "outputs": [],
   "source": [
    "third_model = torch.load(datapath.joinpath('models/simpleNN.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "B5BcgpK9YDRZ",
    "outputId": "d48bb150-16f2-4706-afdb-7784f05b779f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([58.9915,  0.0000,  0.0000,  0.0000,  0.0000, 30.0834,  0.0000, 30.6602,\n",
       "         0.0000,  0.0000,  0.0000,  0.0000, 27.1779,  0.0000, 44.7265,  0.0000,\n",
       "        13.0921, 47.9660,  0.0000,  0.0000], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_model(image_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlCrSWAFYDRZ"
   },
   "source": [
    "And we see that we obtain the same values as above, meaning that the parameters were indeed saved.\n",
    "\n",
    "### Saving the model state\n",
    "\n",
    "Alternatively we can simply save all the parameters, which is a safer method. We simply recover them using ```state_dict```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "OoBQM5drYDRZ"
   },
   "outputs": [],
   "source": [
    "torch.save(third_model.state_dict(),datapath.joinpath('models/simpleNN_state.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WORns8K-YDRZ"
   },
   "source": [
    "To reload the parameters we of course now have to first instantiate the model and \"fill\" it with those values using ```load_state_dict```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "wGZ_UAqhYDRZ"
   },
   "outputs": [],
   "source": [
    "fourth_model = Mynetwork2(1024, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "WxQoeTofYDRa",
    "outputId": "f023dd3b-e0a0-45c8-e688-5592b0385528"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer1.weight',\n",
       "              tensor([[ 0.0006,  0.0285, -0.0012,  ..., -0.0120, -0.0017,  0.0108],\n",
       "                      [-0.0153, -0.0075, -0.0311,  ..., -0.0122, -0.0052, -0.0173],\n",
       "                      [ 0.0219,  0.0307,  0.0298,  ..., -0.0292, -0.0145, -0.0102],\n",
       "                      ...,\n",
       "                      [ 0.0202, -0.0083, -0.0123,  ..., -0.0279,  0.0008, -0.0194],\n",
       "                      [-0.0104, -0.0002,  0.0236,  ...,  0.0193, -0.0260,  0.0115],\n",
       "                      [-0.0140,  0.0290,  0.0227,  ..., -0.0297,  0.0002, -0.0003]])),\n",
       "             ('layer1.bias',\n",
       "              tensor([-0.0247, -0.0022, -0.0153,  0.0309, -0.0280, -0.0003, -0.0287,  0.0284,\n",
       "                      -0.0312,  0.0260, -0.0283, -0.0141, -0.0034, -0.0200, -0.0104, -0.0007,\n",
       "                       0.0278,  0.0278, -0.0049,  0.0208]))])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.load(datapath.joinpath('models/simpleNN_state.pt'))\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "OEBX9c-nYDRa",
    "outputId": "b7dfbf2e-64b4-4c13-d91d-1ad80b6e2195"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fourth_model.load_state_dict(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "z9oYFeQhYDRa",
    "outputId": "e820c7b9-a993-49dd-be0e-9ae7b559cd39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([58.9915,  0.0000,  0.0000,  0.0000,  0.0000, 30.0834,  0.0000, 30.6602,\n",
       "         0.0000,  0.0000,  0.0000,  0.0000, 27.1779,  0.0000, 44.7265,  0.0000,\n",
       "        13.0921, 47.9660,  0.0000,  0.0000], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fourth_model(image_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4x3iMsO-YDRa"
   },
   "source": [
    "## Running on a GPU (run on Colab)\n",
    "\n",
    "If you want to exploit the computational power of a GPU you have to take care of moving **both** the model and the data to it. First, find out if you have a GPU. You can test this for example by running this notebook on Colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 615,
     "status": "ok",
     "timestamp": 1610065588350,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "GmDZf0pBYDRa",
    "outputId": "d3cc82a5-e09a-4b25-b731-efae63e890e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxxUBfwOYDRb"
   },
   "source": [
    "If you have a GPU, you can define it as a device. If not you can fall back on CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 552,
     "status": "ok",
     "timestamp": 1610065594926,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "A-L5ErcoYDRb"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = torch.device(\"cuda\")\n",
    "else:\n",
    "    dev = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_arWP1_YDRb"
   },
   "source": [
    "Now finally if you want to use it with a model you need to move the model to it. Let's check where it currently sits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10919,
     "status": "ok",
     "timestamp": 1610066047097,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "V0wwfn2lY2am",
    "outputId": "f71ec68f-d846-4198-a25d-013b5da6980b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mynetwork2(\n",
       "  (layer1): Linear(in_features=1024, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 581,
     "status": "ok",
     "timestamp": 1610066136339,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "vA7pOTxXawjR",
    "outputId": "9921d8f3-1060-4f0f-8c8d-1d34dd839ff3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0006,  0.0285, -0.0012,  ..., -0.0120, -0.0017,  0.0108],\n",
       "         [-0.0153, -0.0075, -0.0311,  ..., -0.0122, -0.0052, -0.0173],\n",
       "         [ 0.0219,  0.0307,  0.0298,  ..., -0.0292, -0.0145, -0.0102],\n",
       "         ...,\n",
       "         [ 0.0202, -0.0083, -0.0123,  ..., -0.0279,  0.0008, -0.0194],\n",
       "         [-0.0104, -0.0002,  0.0236,  ...,  0.0193, -0.0260,  0.0115],\n",
       "         [-0.0140,  0.0290,  0.0227,  ..., -0.0297,  0.0002, -0.0003]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0247, -0.0022, -0.0153,  0.0309, -0.0280, -0.0003, -0.0287,  0.0284,\n",
       "         -0.0312,  0.0260, -0.0283, -0.0141, -0.0034, -0.0200, -0.0104, -0.0007,\n",
       "          0.0278,  0.0278, -0.0049,  0.0208], requires_grad=True)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(second_model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-_sgXVsbPOU"
   },
   "source": [
    "Now if we try to pass our current image through the network we get an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "executionInfo": {
     "elapsed": 721,
     "status": "error",
     "timestamp": 1610066264714,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "FAqQgKribVaX",
    "outputId": "8c357504-908e-4369-8354-a1c588583af7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([58.9915,  0.0000,  0.0000,  0.0000,  0.0000, 30.0834,  0.0000, 30.6602,\n",
       "         0.0000,  0.0000,  0.0000,  0.0000, 27.1779,  0.0000, 44.7265,  0.0000,\n",
       "        13.0921, 47.9660,  0.0000,  0.0000], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_model(image_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fM379mcZYDRc"
   },
   "source": [
    "The error message is quite explicit: you then need also to move the data, both for training and inference to the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 666,
     "status": "ok",
     "timestamp": 1610066318163,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "prB7rQBoYDRc",
    "outputId": "78b1a0a8-0e5b-4813-91aa-95641a983b4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 579,
     "status": "ok",
     "timestamp": 1610066328705,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "sGgYqbWpYDRc"
   },
   "outputs": [],
   "source": [
    "image_tensor = image_tensor.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "executionInfo": {
     "elapsed": 638,
     "status": "ok",
     "timestamp": 1610066369153,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "_50Ib-_xYDRc"
   },
   "outputs": [],
   "source": [
    "output = second_model(image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 562,
     "status": "ok",
     "timestamp": 1610066373868,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "dDX-VKv9bqrj",
    "outputId": "2e45ed96-3def-4bf7-bf71-482fedc87432"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([58.9915,  0.0000,  0.0000,  0.0000,  0.0000, 30.0834,  0.0000, 30.6602,\n",
       "         0.0000,  0.0000,  0.0000,  0.0000, 27.1779,  0.0000, 44.7265,  0.0000,\n",
       "        13.0921, 47.9660,  0.0000,  0.0000], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oor9GgLbcKXX"
   },
   "source": [
    "The output sits on the GPU and is part of the gradient calcualtion, so if you want to further use it, you will have to pull it from the GPU **and** detach it from gradient calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "pY-wZED3cNBd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([58.991543,  0.      ,  0.      ,  0.      ,  0.      , 30.083395,\n",
       "        0.      , 30.660238,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "       27.177948,  0.      , 44.726513,  0.      , 13.092113, 47.96598 ,\n",
       "        0.      ,  0.      ], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "hlCrSWAFYDRZ"
   ],
   "name": "Simple_NN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
