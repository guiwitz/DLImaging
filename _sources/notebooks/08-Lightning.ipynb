{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6r34vB1VUO7Z"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/guiwitz/DLImaging/blob/master/notebooks/08-Lightning.ipynb)\n",
    "# 8. Simplifying code with PyTorch-Lightning\n",
    "\n",
    "We have seen in the previous chapter how to train a neural network. Our training loop contained a lot of \"boiler-plate\" code, i.e. trivial things that we always need, like ```loss.backwards()```, and that we would like to spare us to write. Several libraries offer such possibilities, the most popular one being PyTorch Lightning. We will here briefly rewrite our code of the [Training](Training.ipynb) notebook with this. You will see that we write essentially the same code, save for some boiler-plate.\n",
    "\n",
    "Another advantage is that the higher-level format offered by Lightning allows us later to simplify complex tasks, like traininig on multiple GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uutXxAoHUO7a",
    "outputId": "66ecb6ec-d19d-4616-d9d9-684eeef6150d",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# set path containing data folder or use default for Colab (/gdrive/My Drive)\n",
    "local_folder = \"../\"\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/guiwitz/DLImaging/master/utils/check_colab.py', 'check_colab.py')\n",
    "from check_colab import set_datapath\n",
    "colab, datapath = set_datapath(local_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqwDnraJUO7b"
   },
   "source": [
    "## Dataloader\n",
    "We recreate first some previous elements. First our dataset and dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3KhAFM52UO7b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.functional import F\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ar51oEkdUO7c"
   },
   "outputs": [],
   "source": [
    "images = np.load(datapath.joinpath('data/triangle_circle.npy'))\n",
    "labels = np.load(datapath.joinpath('data/triangle_circle_label.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "b03vo0E6UO7d"
   },
   "outputs": [],
   "source": [
    "class Tricircle(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        super(Tricircle, self).__init__()\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        x = self.data[index]\n",
    "        x = torch.tensor(x/255, dtype=torch.float32)\n",
    "        y = torch.tensor(self.labels[index])\n",
    "        #y = torch.randint(0,2,(1,))[0]#create random labels as \"bad\" examples\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "x46SkrjpUO7d"
   },
   "outputs": [],
   "source": [
    "tridata = Tricircle(images, labels)\n",
    "test_size = int(0.8 * len(tridata))\n",
    "valid_size = len(tridata)-test_size\n",
    "\n",
    "train_data, valid_data = random_split(tridata, [test_size, valid_size])\n",
    "train_loader = DataLoader(train_data, batch_size=10)\n",
    "validation_loader = DataLoader(valid_data, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9OiYWEXUO7e"
   },
   "source": [
    "## Lightning module\n",
    "\n",
    "Before, we only created an object containing our model and all the remaining tasks - setting up the optimizer, training and validation loop etc. - was done after that \"manually\". Here, all this additional work is included in our object in specific methods (```training_step```, ```validation_step```, ```configure_optimizers```) sparing us a lot of code later on. For example we won't have to explicitly write epochs and batch loops, take care of calculating gradients, setting them to zeros etc.\n",
    "\n",
    "You should understand one important feature of Ligthning: the ```forward``` function is used for **inference** (prediction) while the ```training_step``` is used for **training**. Of course one can include the steps of ```forward``` in the training loop but the latter can contain much more information.\n",
    "\n",
    "The actual difference in code is very small compared to classic PyTorch but brings massive advantages. Of importance in my personal opinion: Lightning *organizes* code and doesn't abstract away complexity. This makes it easy to still do very fine adjustments to the underlying PyTorch code what other higher-level frameworks make difficult.\n",
    "\n",
    "This was our previous code defining our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5T8XG8xvUO7f"
   },
   "outputs": [],
   "source": [
    "class Mynetwork(nn.Module):\n",
    "    def __init__(self, input_size, num_categories):\n",
    "        super(Mynetwork, self).__init__()\n",
    "        \n",
    "        # define e.g. layers here e.g.\n",
    "        self.layer1 = nn.Linear(input_size, 100)\n",
    "        self.layer2 = nn.Linear(100, num_categories)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # flatten the input\n",
    "        x = x.flatten(start_dim=1)\n",
    "        # define the sequence of operations in the network including e.g. activations\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = self.layer2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyTpul5xUO7g"
   },
   "source": [
    "Now we add methods for training, validation and optimizer which are basically copied from our previous work. Note however that we can skip many things, like loops or ```backward()``` calls. The only thing that we are adding are calls to ```self.log``` which allows us to capture and display loss, accuracy etc. information during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "wSTK--TUUO7g"
   },
   "outputs": [],
   "source": [
    "class Mynetwork(pl.LightningModule):\n",
    "    def __init__(self, input_size, num_categories):\n",
    "        super(Mynetwork, self).__init__()\n",
    "        \n",
    "        # define e.g. layers here e.g.\n",
    "        self.layer1 = nn.Linear(input_size, 100)\n",
    "        self.layer2 = nn.Linear(100, num_categories)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # flatten the input\n",
    "        x = x.flatten(start_dim=1)\n",
    "        # define the sequence of operations in the network including e.g. activations\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = self.layer2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        x, y = batch\n",
    "        output = self(x)\n",
    "        loss = self.loss(output, y)\n",
    "        \n",
    "        self.log('loss', loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        x, y = batch\n",
    "        output = self(x)\n",
    "        accuracy = (torch.argmax(output,dim=1) == y).sum()/len(y)\n",
    "\n",
    "        self.log('accuracy', accuracy, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        return accuracy\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXn3e6WtUO7h"
   },
   "source": [
    "Now we instantiate the Lightning module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Y2B3r3jgUO7h"
   },
   "outputs": [],
   "source": [
    "model = Mynetwork(32*32, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ma_R7fFyUO7i"
   },
   "source": [
    "## Training\n",
    "\n",
    "Instead of writing a training loop for epochs and batches, we use the Lightning ```Trainer``` object which takes care of everything for us. We first instantiate it and then pass our model and data loaders for fitting (similarly to scikit-learn methods). When creating the ````Trainer```` object, we can pass a large number of parameters, the most common being the number of epochs or the usage of GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cGZcq07EUO7j",
    "outputId": "487f6f9c-edcf-4552-8c1a-dc73382c2ac1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270,
     "referenced_widgets": [
      "3132a96b619f4ec0889b83b3d3c7da42",
      "c8c02c6f43404daeaa857a57493605c9",
      "8cf1a7c50e1147a6a0677691b47fb019",
      "1f78a93fade8492b9287d68af7ffba83",
      "59b6fa794bce4f7fba153b40752134f3",
      "0d25c04306144f9e8848f800782fa28d",
      "9e3280680add4ea896ddf39d2160b65f",
      "8a3af0df87444ef497629f4f0780e95a",
      "6fc5164339f64ab38472c619458a03b6",
      "f90f88659b1f45ba9f61ea50e2e1bc52",
      "70c5b3c5883542c1babfb380acc9eb61",
      "62ab4e216938445b88685394543ea2c7",
      "0ac2c76689d54acdb702ca74b349cee5",
      "1979c28fd3a949a096961313be5d115f",
      "4397294b85ac45cf909a759dcd0a65c9",
      "0b45b5267e474b7b9c3d59db4784f1da",
      "44d9d72a155042c5a7413b678934097f",
      "317f2ea8d292423b9d11cacf6c17c2c0",
      "fc9d6a25f6154083a86dd36bd41f8de4",
      "f1d21d34a51440a68f6bc2c90d4a7bd2",
      "3db702f2900f4cbc894874f7cd7bf922",
      "2a91f53d8b5f4fc2a9d84b03c2e821cf",
      "02cb72eb92e24e899319f823fa4a7cfc",
      "0ee0920efec94dd48ed6b2ca53f8149e",
      "4d391faa5a0a4127b24c1feb50536bf0",
      "4b02f954c3b042ba85dfdc561e98ca53",
      "1600d9eb50e74eb9a2d8192baa8c1a96",
      "c08cf76625f74bfe845195d8d6c9580e",
      "e090cf7e53224d489f90f0893fb87afd",
      "2395d635773a4ab691c306b3a4a362e6",
      "c22173e7ead34f33be861badab65ec73",
      "3d3a9be2ca774003b11df8336f3327f7",
      "7e438f903f744eb0b885255fbd5e8eca"
     ]
    },
    "id": "eM9FL8WBUO7k",
    "outputId": "679ee61f-7de0-4af7-9bfe-4b4be35aee79"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type             | Params\n",
      "--------------------------------------------\n",
      "0 | layer1 | Linear           | 102 K \n",
      "1 | layer2 | Linear           | 202   \n",
      "2 | loss   | CrossEntropyLoss | 0     \n",
      "--------------------------------------------\n",
      "102 K     Trainable params\n",
      "0         Non-trainable params\n",
      "102 K     Total params\n",
      "0.411     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                              "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gw18g940/miniconda3/envs/CASImaging/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/gw18g940/miniconda3/envs/CASImaging/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 5000/5000 [00:54<00:00, 91.54it/s, loss=0.00865, v_num=6, loss_step=0.0378, accuracy=0.998, loss_epoch=0.0292]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=validation_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTclhAAzUO7l"
   },
   "source": [
    "## Inference\n",
    "\n",
    "To check that trainig worked, we just generate again some images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "OSj3zN5-UO7l"
   },
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/guiwitz/DLImaging/master/notebooks/dlcourse.py', 'dlcourse.py')\n",
    "from dlcourse import make_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6eg5C01CUO7n"
   },
   "outputs": [],
   "source": [
    "im_type = ['triangle', 'circle']\n",
    "label = torch.tensor(np.random.randint(0,2,100))\n",
    "mybatch = torch.stack([make_image(im_type[x]) for x in label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SEmseLP6UO7o",
    "outputId": "894e48b9-1fe1-4f35-e053-3b1eccdd7409"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 32, 32])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybatch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "nBuVxZgcUO7o"
   },
   "outputs": [],
   "source": [
    "pred = model(mybatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rtsmW3PmUO7r",
    "outputId": "e313515e-f0c2-449d-9c45-e002acf58a02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "        1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "        0, 1, 1, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "423V3Q25UO7s",
    "outputId": "d25df2ac-4ce7-4244-e3fb-1d1d58e0c961"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "        1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "        0, 1, 1, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "4MlB6mpxUO7t"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "aaJ_Cd2tUO7t"
   },
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(confusion_matrix(pred.argmax(dim=1), label), index = im_type,\n",
    "                  columns = im_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "dm6czts8UO7v",
    "outputId": "850ca7f3-aee8-45a9-ee6b-3b984aa97287"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WlCYcUhIUO7v"
   },
   "source": [
    "## Using a logger\n",
    "\n",
    "It is very common to use an additional tool to follow the progress of training. A very popular tool is TensorBoard. To use it with PyTorch Lightening, we can simply attach a TensorBoard logger to our trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "6W2VzCxFUO7w"
   },
   "outputs": [],
   "source": [
    "class Mynetwork(pl.LightningModule):\n",
    "    def __init__(self, input_size, num_categories):\n",
    "        super(Mynetwork, self).__init__()\n",
    "        \n",
    "        # define e.g. layers here e.g.\n",
    "        self.layer1 = nn.Linear(input_size, 100)\n",
    "        self.layer2 = nn.Linear(100, num_categories)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # flatten the input\n",
    "        x = x.flatten(start_dim=1)\n",
    "        # define the sequence of operations in the network including e.g. activations\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = self.layer2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        x, y = batch\n",
    "        output = self(x)\n",
    "        \n",
    "        loss = self.loss(output, y)\n",
    "        accuracy = (torch.argmax(output,dim=1) == y).sum()/len(y)\n",
    "        \n",
    "        self.log(\"Loss/Train\", loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"Accuracy/Train\", accuracy, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        x, y = batch\n",
    "        output = self(x)\n",
    "        \n",
    "        loss = self.loss(output, y)\n",
    "        accuracy = (torch.argmax(output,dim=1) == y).sum()/len(y)\n",
    "\n",
    "        self.log(\"Loss/Valid\", loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"Accuracy/Valid\", accuracy, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        return accuracy\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "bKRsh5bgUO7w"
   },
   "outputs": [],
   "source": [
    "model = Mynetwork(32*32, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JnJzwPErUO7x"
   },
   "source": [
    "We added here logging of the accuracy and loss for both training and validation using the ```add_scalar``` method. You can find more details in the [PyTorch API](https://pytorch.org/docs/stable/tensorboard.html).\n",
    "\n",
    "Now we create a tensorboard logger and pass it to our trainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lyP4CxoVUO7x",
    "outputId": "e9cc3dfb-ec7e-48f6-ae29-bea485a14700"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"my_model\")\n",
    "trainer = pl.Trainer(logger=logger, max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307,
     "referenced_widgets": [
      "41cf5b0a4fa246da938bb90a04dffa55",
      "3f4b89bb377840e48cb482fa3a7e2cfa",
      "8071e188bfdf440da66f2b7b6a5615f8",
      "39ef5345c0f345d8b3e5568f0ceef6cb",
      "50be90c8cd3c49378e7a32a4d0656193",
      "b039d01a4d6b48579ec62a891a83abba",
      "f914aebb807a4098a9b18646089fc820",
      "1280a8116220445f819f4cf5ceb4e5d8",
      "c39d397b36de4ee48d92b4ce9207c326",
      "88cbefc4602041a080453f2ba2b330fd",
      "fe673076b5ba41929e46cde2c09be4f5",
      "43af798982d0461ea17cebaff37cf2b7",
      "328466535c9a44e5891cb65b62193946",
      "4da25e3354a24b7d83999408ddea7015",
      "b06cff54cbac493098b63589743be9a5",
      "60aee2ea166342ab96eef90e9a37c905",
      "4368049acdc34a14a4dcdadfbb19f5ba",
      "6c702ef99bba46b9af4f86e808f27f4d",
      "e2e403de229c45f68eac46f13d376e67",
      "07a4eb12b8964a9a8534a6bfeb2fd6f4",
      "ce6fd4c71512478fbd1bfbf810e26514",
      "b9092291a8a54f55b380034db804b2ae",
      "80f9e578ff0543c5b15432b889b17c7f",
      "98d8a1f861564874a34a03669cd42124",
      "86f7986c35954461a3b3209a5a297e9b",
      "219e3e1f5dc3402db28c7fa9bb0d343d",
      "495d0b5ae48b439a9835950f5b894177",
      "ec785e8f716844089eb8c02180081572",
      "8111fe1d25dc4938a7411f524ce33f3a",
      "e189b2872e2b4e8d845bc34b378e6812",
      "c611dc4200474ce9934b52d5919cb85e",
      "1a14892a28f84e11b759da4748eab5fd",
      "74728224fda04efcbb6f0b1b768fb7d2",
      "3a1888c827b048fc922b3fdacbe1b384",
      "0079e8d442444637b266b2c699d883d4",
      "5cfce259356d41a195345412a669fb9c",
      "3af6c98a7181422eb2b32ade2e275a17",
      "2d6489186e234a7ba133dd6c2f50dc53",
      "04702ccb5baf40d0a3177c7b2851fd8e",
      "d19694820e7747ddb69f211e66657c67",
      "ce682bec2cef4ba58427fdfef90e25ca",
      "98b5baf9244e40f3a89c36b73e51a179",
      "05da7da9a23243f79e335d1eac8e05db",
      "b64b7bd5fe014005a8db0cb7ffade258",
      "d911f3eb30f446e0ac88dda9913d48ad",
      "3bb93d0a93d543e596728895da1ae076",
      "25787bd1849c46ecbb3e9c16070b71b9",
      "91978dd06a1949e799e971fd54f276cc",
      "887d895b804045ea915f5048355dc2a9",
      "8e8853266a3042d3a4e7f2d5809736af",
      "f8e2b85f38fe43f3b46385490c9bdb53",
      "dbb417d087f140e59abd5782a61811b7",
      "c06a63b99c984b27a48b8fea56cbab82",
      "86052101cd3142cf97891c8a421574e1",
      "3bae97db76744285bc04164914429eba"
     ]
    },
    "id": "eiR6rXWEUO7y",
    "outputId": "cd9dffa2-8543-474f-b015-96118fb8799f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type             | Params\n",
      "--------------------------------------------\n",
      "0 | layer1 | Linear           | 102 K \n",
      "1 | layer2 | Linear           | 202   \n",
      "2 | loss   | CrossEntropyLoss | 0     \n",
      "--------------------------------------------\n",
      "102 K     Trainable params\n",
      "0         Non-trainable params\n",
      "102 K     Total params\n",
      "0.411     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                              "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gw18g940/miniconda3/envs/CASImaging/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/gw18g940/miniconda3/envs/CASImaging/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  16%|█▌        | 800/5000 [00:15<01:23, 50.12it/s, loss=0.00446, v_num=4, Loss/Train_step=8.46e-7, Accuracy/Train_step=1.000, Loss/Valid=0.00836, Accuracy/Valid=0.999, Loss/Train_epoch=0.00965, Accuracy/Train_epoch=0.998] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gw18g940/miniconda3/envs/CASImaging/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Ghxf0PbwUO7y"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ad10e41b263f498e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ad10e41b263f498e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  16%|█▌        | 800/5000 [00:33<02:53, 24.24it/s, loss=0.00446, v_num=4, Loss/Train_step=8.46e-7, Accuracy/Train_step=1.000, Loss/Valid=0.00836, Accuracy/Valid=0.999, Loss/Train_epoch=0.00965, Accuracy/Train_epoch=0.998]"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir tb_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBEG2e5MUO7z"
   },
   "source": [
    "## Running on the GPU\n",
    "\n",
    "We have seen in a previous notebook that in order to use a GPU we need to send models and data to it. This is much simplified with Lightning, as you just have to tell the trainer to use a GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WFivx-QfUO7z",
    "outputId": "6e358651-3d0c-46f7-bca2-65742ac1ccbf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(logger=logger, max_epochs=10, gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341,
     "referenced_widgets": [
      "5cfb7b9adf8b42ec83174141b2217062",
      "4f7454175ff04c5ba5c126bce0365215",
      "08fa3b907c804359a337f90a37ce6cdc",
      "6bccfde9f7e34921bcc174a04f3ab217",
      "e018b7d394a64182bd2fc5d07af6353d",
      "825d51c80134417484d6afa716142e56",
      "1c730cd002644d739db22da7aa312047",
      "e1daa0ceeccd47d282c83e79a6f96df0",
      "85268f13859846bb8914fb03cf38e88c",
      "0702c31eb7da448ba878bc335a6c70f1",
      "d04ffb2e043c4069abcb0aa8be9a8823",
      "8715b0623f4445e1b01380a8ce21af0a",
      "1d31e43e06ef47469c1ae26f95c94b85",
      "be52c3f82f054895bb6f0b6026d74ccd",
      "9e218361b4944b76acf93ca091f308a6",
      "b1ca8be103284496abebc9ac6b65de62",
      "2e5e6527fcc945b9a1b8104b2fc583f6",
      "66bf8603fc15421fb1c1aed542c17aad",
      "e66a3b70c65841a2af491b2971862794",
      "fe71faa9910147bbb581964ce061ed00",
      "bb282083eb084b3491f07bfcab48e853",
      "21e8d5e48b8d4a50b2b899f1dd654bef",
      "1f9bba08d5ff41c68a564cd969aa3f68",
      "dc3703ff2d954a0eb3941fb72f4145f5",
      "7349df6abcfa43bfaa02bed1aaeabfe7",
      "8bcb5782b0de4b8894ac10abd8dbdf10",
      "8c7faf55410648ae9e08e3eafd18a47f",
      "f0b15645cee64ec8a4d9f35502f9c49f",
      "3772fae521674707abf882da0295ec18",
      "d36197cd550846b687627f4c43629622",
      "3664f7f1f5454f3e9abb902b90ed407a",
      "bfe99be132f14431bd519684ebae8e14",
      "31945705daa84b30b829a147506bc1eb",
      "ec4e878273094abfb37cfc6752112284",
      "70ba050cd4844f3db70e86e2b7c777b1",
      "b26365f94bdf482bb4cb1581b619b14d",
      "b41b90fa33c3496580f55db0182ddc7e",
      "14db3925a1cb4011ba0bf6ef8a23ab5c",
      "d98ba0dc02744ed08cdf478843f77984",
      "b6dbe6f617d54697a07cc9d57cfcb51d",
      "ab41de46555543b1b79befafb36305a7",
      "e87e56e3e76d44d59c488bef7861c356",
      "b104f8a9d7ae4f93b191755a1d50d5f3",
      "271b574b05df42feb24b68d7d7ee81eb"
     ]
    },
    "id": "xQbnYpscbYH2",
    "outputId": "e4b6b8a6-5983-4178-ea26-cfee515db6d2"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=validation_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoints\n",
    "\n",
    "Especially if you are running a very long training, you don't want to save only the *very last* state of your model, with the risk to loose all the training if the session gets interrupted. To avoid this you can keep intermediate states of your training as **checkpoints**. One can do this manually, but frameworks like Lightening simplify this task. \n",
    "\n",
    "Actually, by default Lighting saves the state of the training of the last epoch and you can find this in a local folder called ```lighting_logs```. That folder might contain multiple ```versions``` of your training, each containing a ```checkpoints``` folder with a file named something like  ```epoch=0-step=3999.ckpt```. That file contains much more information than just the parameters of the network, such as the current learning rate, the state of the optimizer etc. Also the initiatlization parameters or *hyper parameters* used to instantiate your model are saved.\n",
    "\n",
    "The default folder of the checkpoints can be overridden when creating the trainer using the ```default_root_dir``` option but if you use a logger (as done above) the checkpoints will be in the logging folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    default_root_dir=\"mylogs\", max_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type             | Params\n",
      "--------------------------------------------\n",
      "0 | layer1 | Linear           | 102 K \n",
      "1 | layer2 | Linear           | 202   \n",
      "2 | loss   | CrossEntropyLoss | 0     \n",
      "--------------------------------------------\n",
      "102 K     Trainable params\n",
      "0         Non-trainable params\n",
      "102 K     Total params\n",
      "0.411     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                              "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gw18g940/miniconda3/envs/CASImaging/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/gw18g940/miniconda3/envs/CASImaging/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  10%|▉         | 482/5000 [00:06<01:01, 74.04it/s, loss=0.0387, v_num=1, Loss/Train_step=0.0207, Accuracy/Train_step=1.000, Loss/Valid=0.0592, Accuracy/Valid=0.987, Loss/Train_epoch=0.174, Accuracy/Train_epoch=0.932]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gw18g940/miniconda3/envs/CASImaging/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "model = Mynetwork(32*32, 2)\n",
    "\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=validation_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading checkpoints\n",
    "\n",
    "There are multiple ways of reloading the state depending on your needs. For example you can restore the weights of your network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Mynetwork.load_from_checkpoint(\n",
    "    'mylogs/lightning_logs/version_0/checkpoints/epoch=0-step=3999.ckpt',\n",
    "    input_size=32*32, num_categories=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can avoid having to pass the ```input_size``` and ```num_categories``` options if you also save these hyper-parameters. For that you have to use the ```self.save_hyperparameters()``` function in your Lightning module:\n",
    "\n",
    "```python\n",
    "class Mynetwork(pl.LightningModule):\n",
    "    def __init__(self, input_size, num_categories):\n",
    "        super(Mynetwork, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case for example where your training has been interrupted, you might want to re-load the full state, including epoch, learning rate etc. You can do that directly in the ```fit``` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    default_root_dir=\"mylogs\", max_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at mylogs/lightning_logs/version_1/checkpoints/epoch=0-step=3999.ckpt\n",
      "/Users/gw18g940/miniconda3/envs/CASImaging/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:247: UserWarning: You're resuming from a checkpoint that ended mid-epoch. Training will start from the beginning of the next epoch. This can cause unreliable results if further training is done, consider using an end of epoch checkpoint.\n",
      "  rank_zero_warn(\n",
      "Restored all states from the checkpoint file at mylogs/lightning_logs/version_1/checkpoints/epoch=0-step=3999.ckpt\n",
      "\n",
      "  | Name   | Type             | Params\n",
      "--------------------------------------------\n",
      "0 | layer1 | Linear           | 102 K \n",
      "1 | layer2 | Linear           | 202   \n",
      "2 | loss   | CrossEntropyLoss | 0     \n",
      "--------------------------------------------\n",
      "102 K     Trainable params\n",
      "0         Non-trainable params\n",
      "102 K     Total params\n",
      "0.411     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  36%|███▋      | 1821/5000 [00:28<00:49, 64.16it/s, loss=0.037, v_num=2, Loss/Train_step=0.0312, Accuracy/Train_step=1.000]   "
     ]
    }
   ],
   "source": [
    "model = Mynetwork(32*32, 2)\n",
    "\n",
    "trainer.fit(\n",
    "    model, train_dataloaders=train_loader, val_dataloaders=validation_loader,\n",
    "    ckpt_path='mylogs/lightning_logs/version_1/checkpoints/epoch=0-step=3999.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RT33Ud7xUO70"
   },
   "source": [
    "## Exercise\n",
    "\n",
    "We have seen here and in the previous chapters how to create datasets, dataloaders, transforms and a easily trainable Lightning-network. In a previous exercise you have in particular created a dataloader for the quickdraw dataset. Extend this now by creating a Lightninig-network with a simple NN similar to the one used here. Try to train it. (Answer is notebook [09-Classify_drawings](09-Classify_drawings.ipynb))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1166QaTyUO70"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "08-Lightning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
